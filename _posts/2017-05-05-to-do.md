---
layout:     post
title:      "No Title"
date:       2017-05-05
summary:    Playing around with books from project Gutenberg.
categories: nlp ml
---

### Prologue: In Which the Author Explains Why He's Doing What He's Doing

Books are fun. <sup>[[citation needed](https://xkcd.com/285)]</sup> 

What's even more fun are vector space models, clustering algorithms, and dimensionality reduction techniques. In this blog post, we're going to combine it all by playing around with a small set of texts from project Gutenberg. With a bit of luck, Python, and lots of trial and error, we might just learn something interesting.

### Chapter One: In Which Books are Fetched and Puns are Made
We should start by fetching some books. There are many ways to do it, but for starters let's just use what NLTK has to offer: 

```python
>>> from nltk.corpus import gutenberg
>>> fileids = gutenberg.fileids()
>>> fileids
['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt',
 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt',
 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt',
 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt',
 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt',
 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']
```

This rather eclectic collection will serve as our dataset. How about we weed out the boring books (your definition of boring may vary):

```python
>>> boring = ['bible-kjv.txt',
...           'edgeworth-parents.txt',
...           'melville-moby_dick.txt'] 
>>> titles = [fileid for fileid in fileids if fileid not in boring] 
>>> texts = [gutenberg.raw(title) for title in titles] 
```

Let's also be pedantic and use some regexp magic to strip the titles:

```python
>>> titles = [re.search(r'-(.*?)\.', title).group(1) for title in titles] 
>>> titles
['emma', 'persuasion', 'sense',
 'poems', 'stories', 'busterbrown', 
 'alice', 'ball', 'brown',
 'thursday', 'paradise', 'caesar',
 'hamlet', 'macbeth', 'leaves']
```

Conveniently (and completely coincidentally) the remaining titles fall into five distinct categories I spent far too much time naming:
- Darcy and Company: `emma`, `persuasion`, `sense` 
- Bard's Tales: `caesar`, `macbeth`, `hamlet`
- Chestertomes: `ball`, `brown`, `thursday`
- BMW (Blake, Milton, Whitman): `poems`, `paradise`, `leaves`
- BBC (Bryant, Burgess, Carroll): `stories`, `buster`, `alice`

In other words, our modest library contains three Jane Austen's novels, three Shakespeare's plays, three novels by Gilbert K. Chesterton, three poem collections, and three children books (I'm sorry, Mr. Carroll). Let's find out if this classification is equally intuitive to a computer.

### Chapter Two: In which Books are Magically Turned into Numbers and What Happens Then
Before we can run any machine learning algorithm on text documents, we need to find a numerical representation. One idea could be to represent each text as an indicator vector:


[^1]: [Don't mention Macbeth](https://www.youtube.com/watch?v=h--HR7PWfp0) 
